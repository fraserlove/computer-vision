{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448923ee-c29e-435e-9954-1eed47172abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the datatset from Kaggle.\n",
    "!kaggle datasets download -p datasets/flowers-recognition -d alxmamaev/flowers-recognition --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff7bfd-3102-4f3a-9dfc-ef94411a69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78e494-966f-4449-bb05-1b40e31d116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "data = []\n",
    "for file in glob.glob('datasets/flowers-recognition/flowers/*'):\n",
    "    label = file.split('/')[-1]\n",
    "    for img in glob.glob(f'{file}/*.jpg'):\n",
    "        data.append((img, label)) \n",
    "\n",
    "print(f'There are {len(data)} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22686e4-6e52-4021-aa2b-75f2c0354893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data before partitioning\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data into train, validation and test sets\n",
    "train, val, test = np.split(data, [int(len(data) * 0.7), int(len(data) * 0.8)])\n",
    "\n",
    "train_df = pd.DataFrame({'image':train[:,0], 'label':train[:,1]})\n",
    "val_df = pd.DataFrame({'image':val[:,0], 'label':val[:,1]})\n",
    "test_df = pd.DataFrame({'image':test[:,0], 'label':test[:,1]})\n",
    "\n",
    "print(f'There are {len(train_df)} images for training')\n",
    "print(f'There are {len(val_df)} images for validation')\n",
    "print(f'There are {len(test_df)} images for testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a958922-ba5b-4650-9ec4-3499b7632830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the CNN 32 images at a time. The lower the batch size, the better the model will learn,\n",
    "# however, the training process will be longer.\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Create the ImageDataGenerator object and rescale the images\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Convert them into a dataset to be split into batches, shuffled and resized\n",
    "train_dataset = image_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    class_mode='categorical',\n",
    "    x_col='image',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    ")\n",
    "\n",
    "val_dataset = image_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    class_mode='categorical',\n",
    "    x_col='image',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    ")\n",
    "\n",
    "test_dataset = image_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    class_mode='categorical',\n",
    "    x_col='image',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    ")\n",
    "\n",
    "train_images, train_labels = next(iter(train_dataset))\n",
    "\n",
    "print(f'Batch shape: {train_images.shape}')\n",
    "print(f'Label shape: {train_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9432629-991f-4d6d-aa1c-51a7a9507af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data by plotting the first few images in the dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.imshow(train_images[i]/ 255)\n",
    "    plt.xlabel(class_names[np.argmax(train_labels[i])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb5809-1692-4508-a074-fdb2d1da8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning with a pre-trained model from Keras Applications\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), pooling='avg')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Freezing the weights in the base model since it is pre-trained\n",
    "base_model.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b85f97-d92c-415c-8a88-6fd4a921f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the algorithm for backpropagation, the loss function and a performace metric\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Stop training early if the validation loss is constant or increasing for more than 3 epochs\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2cfd41-7bd2-472c-8f5c-9c19b78c3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, batch_size=32, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580d6ab-de9b-4f2a-a66e-7e051a18e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric='loss'):\n",
    "    plt.title(metric.capitalize())\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[f'val_{metric}'])\n",
    "    plt.xlabel('Epoch'), plt.ylabel(metric.capitalize())\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the network\n",
    "plot_metric(history, 'loss')\n",
    "plot_metric(history, 'accuracy')\n",
    "\n",
    "# Test the network on unseen data\n",
    "loss, acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509edfaf-4f49-46b2-9b72-d66bbc659a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(url):\n",
    "    image = plt.imread(tf.keras.utils.get_file(origin=url))\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = np.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "image = process_image('https://upload.wikimedia.org/wikipedia/commons/c/c4/Tulipa_orphanidea_060506.jpg')\n",
    "predictions = model.predict(image)\n",
    "print(predictions)\n",
    "\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.xlabel(f'{class_names[np.argmax(predictions[0])]} ({np.max(predictions):.2f})')\n",
    "plt.imshow(image[0,:,:,:] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74edf199-cc5e-4ccd-ad7e-dd07b276c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('saved/image-classifier-flowers-recognition.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
