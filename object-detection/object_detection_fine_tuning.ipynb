{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the datatset from Kaggle.\n",
    "!kaggle datasets download -p datasets/face-recognition -d sbaghbidi/human-faces-object-detection --unzip\n",
    "# Split CSV into training, validation and testing data\n",
    "!python csv_split_dataset.py --csv datasets/face-recognition/faces.csv --images datasets/face-recognition/images\n",
    "# Convert CSV to TFRecord\n",
    "!python csv_to_tfrecord.py --input_path datasets/face-recognition/train/faces.csv --output_path datasets/face-recognition/train/faces.record\n",
    "!python csv_to_tfrecord.py --input_path datasets/face-recognition/val/faces.csv --output_path datasets/face-recognition/val/faces.record\n",
    "!python csv_to_tfrecord.py --input_path datasets/face-recognition/test/faces.csv --output_path datasets/face-recognition/test/faces.record\n",
    "# Create a label map for this dataset\n",
    "!echo \"item { id: 1 name: 'face' }\" > datasets/face-recognition/label_map.pbtxt\n",
    "\n",
    "# Download and install TensorFlow Object Detection API\n",
    "!brew install protobuf\n",
    "!git clone --depth 1 https://github.com/tensorflow/models\n",
    "%cd models/research/\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install .\n",
    "%cd ../../\n",
    "\n",
    "# Set up directory structure\n",
    "!mkdir pre-trained-models\n",
    "!mkdir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Import the TensorFlow Object Detection API visualisation tools\n",
    "from object_detection.utils import config_util, label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.protos import pipeline_pb2\n",
    "\n",
    "# Display plots in Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
    "model_url = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL}.tar.gz'\n",
    "MODEL_DIR = str(tf.keras.utils.get_file(fname=MODEL, origin=model_url, cache_dir='pre-trained-models/', untar=True))\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(f'{MODEL_DIR}/pipeline.config')\n",
    "\n",
    "configs['model'].ssd.num_classes = 1\n",
    "configs['train_config'].batch_size = 2\n",
    "configs['train_config'].fine_tune_checkpoint = f'{MODEL_DIR}/checkpoint/ckpt-0'\n",
    "configs['train_config'].num_steps = 10000\n",
    "configs['train_config'].fine_tune_checkpoint_type= 'detection'\n",
    "configs['train_input_config'].label_map_path = 'datasets/face-recognition/label_map.pbtxt'\n",
    "configs['train_input_config'].tf_record_input_reader.input_path[0] = 'datasets/face-recognition/train/faces.record'\n",
    "configs['eval_input_config'].label_map_path = 'datasets/face-recognition/label_map.pbtxt'\n",
    "configs['eval_input_config'].tf_record_input_reader.input_path[0] = 'datasets/face-recognition/val/faces.record'\n",
    "\n",
    "pipeline_proto = config_util.create_pipeline_proto_from_configs(configs)\n",
    "config_util.save_pipeline_config(pipeline_proto, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir training/ssd_mobilenet_v2_320x320_coco17_tpu-8/train/\n",
    "!python models/research/object_detection/model_main_tf2.py --model_dir=training/ssd_mobilenet_v2_320x320_coco17_tpu-8 --pipeline_config_path=pre-trained-models/datasets/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "!python models/research/object_detection/model_main_tf2.py --model_dir=training/ssd_mobilenet_v2_320x320_coco17_tpu-8 --pipeline_config_path=pre-trained-models/datasets/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config --checkpoint_dir=training/ssd_mobilenet_v2_320x320_coco17_tpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    print(f'Loading image - {path}')\n",
    "    if path.startswith('http'):\n",
    "        return np.array(Image.open(tf.keras.utils.get_file(origin=path)))\n",
    "    return np.array(Image.open(path)) \n",
    "\n",
    "def load_label_map(path):\n",
    "    print(f'Loading label map - {path}')\n",
    "    return label_map_util.create_category_index_from_labelmap(path)\n",
    "\n",
    "def load_model(checkpoint_dir):\n",
    "    latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    print(f'Loading checkpoint - {latest_ckpt}')\n",
    "    # Load pipeline config\n",
    "    configs = config_util.get_configs_from_pipeline_file(f'{MODEL_DIR}/pipeline.config')\n",
    "    model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "    # Restore checkpoint\n",
    "    ckpt = tf.compat.v2.train.Checkpoint(model=model)\n",
    "    ckpt.restore(latest_ckpt).expect_partial()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image included in TensorFlow Object Detection API.\n",
    "IMAGE_PATH = 'https://upload.wikimedia.org/wikipedia/commons/a/a0/Pierre-Person.jpg'\n",
    "LABEL_MAP_PATH = 'datasets/face-recognition/label_map.pbtxt'\n",
    "CHECKPOINT_PATH = 'training/ssd_mobilenet_v2_320x320_coco17_tpu-8/' # Path to last checkpoint created while training\n",
    "\n",
    "image = load_image(IMAGE_PATH)\n",
    "labels = load_label_map(LABEL_MAP_PATH)\n",
    "model = load_model(CHECKPOINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
